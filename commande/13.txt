root@hadoop-master:~# JAR=$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.2.0.jar
root@hadoop-master:~# hadoop jar $JAR -files mapper.py,reducer.py -mapper mapper.py -reducer reducer.py  -input data_in -output data_out2
packageJobJar: [/tmp/hadoop-unjar9025694058720473949/] [] /tmp/streamjob2284498597299015987.jar tmpDir=null
2020-01-20 14:17:55,626 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032
2020-01-20 14:17:56,006 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032
2020-01-20 14:17:56,258 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1579510870151_0003
2020-01-20 14:17:56,631 WARN hdfs.DataStreamer: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.endBlock(DataStreamer.java:640)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:810)
2020-01-20 14:17:56,835 INFO mapred.FileInputFormat: Total input files to process : 4
2020-01-20 14:17:56,911 INFO mapreduce.JobSubmitter: number of splits:5
2020-01-20 14:17:56,954 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2020-01-20 14:17:57,125 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1579510870151_0003
2020-01-20 14:17:57,127 INFO mapreduce.JobSubmitter: Executing with tokens: []
2020-01-20 14:17:57,424 INFO conf.Configuration: resource-types.xml not found
2020-01-20 14:17:57,425 INFO resource.ResourceUtils: Unable to find resource-types.xml.
2020-01-20 14:17:57,560 INFO impl.YarnClientImpl: Submitted application application_1579510870151_0003
2020-01-20 14:17:57,656 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1579510870151_0003/
2020-01-20 14:17:57,658 INFO mapreduce.Job: Running job: job_1579510870151_0003
2020-01-20 14:18:06,974 INFO mapreduce.Job: Job job_1579510870151_0003 running in uber mode : false
2020-01-20 14:18:06,982 INFO mapreduce.Job:  map 0% reduce 0%
2020-01-20 14:18:29,527 INFO mapreduce.Job:  map 100% reduce 0%
2020-01-20 14:18:37,648 INFO mapreduce.Job:  map 100% reduce 100%
2020-01-20 14:18:38,720 INFO mapreduce.Job: Job job_1579510870151_0003 completed successfully
2020-01-20 14:18:39,158 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=6425
		FILE: Number of bytes written=1364559
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4518
		HDFS: Number of bytes written=3272
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=5
		Launched reduce tasks=1
		Data-local map tasks=5
		Total time spent by all maps in occupied slots (ms)=100377
		Total time spent by all reduces in occupied slots (ms)=5273
		Total time spent by all map tasks (ms)=100377
		Total time spent by all reduce tasks (ms)=5273
		Total vcore-milliseconds taken by all map tasks=100377
		Total vcore-milliseconds taken by all reduce tasks=5273
		Total megabyte-milliseconds taken by all map tasks=102786048
		Total megabyte-milliseconds taken by all reduce tasks=5399552
	Map-Reduce Framework
		Map input records=170
		Map output records=666
		Map output bytes=5087
		Map output materialized bytes=6449
		Input split bytes=525
		Combine input records=0
		Combine output records=0
		Reduce input groups=368
		Reduce shuffle bytes=6449
		Reduce input records=666
		Reduce output records=368
		Spilled Records=1332
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=1552
		CPU time spent (ms)=2900
		Physical memory (bytes) snapshot=1057325056
		Virtual memory (bytes) snapshot=15514546176
		Total committed heap usage (bytes)=719736832
		Peak Map Physical memory (bytes)=190550016
		Peak Map Virtual memory (bytes)=2585407488
		Peak Reduce Physical memory (bytes)=108556288
		Peak Reduce Virtual memory (bytes)=2591719424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3993
	File Output Format Counters 
		Bytes Written=3272
2020-01-20 14:18:39,167 INFO streaming.StreamJob: Output directory: data_out2
root@hadoop-master:~# hadoop fs -cat data_out/part-r-00000
Aimant	1
Ainsi	1
Bien	1
Cest	2
CAREME	1
Chaque	1
Demain,	2
Dit	1
Du	1
ELUARD	1
Et	5
GAUTIER	1
HUGO	1
Harfleur,	1
II	2
Il	1
Jai	1
Jirai	1
Jecris	20
Jamais	1
Je	9
Lenfant	1
La	1
Le	2
Liberte	1
Liberte.	1
Mais	1
Maurice	1
Mon	1
Ni	2
Orange.	1
Orne	1
Parfois	1
Paul	1
Petit	1
Pierre	1
Pour	2
Quil	1
Sans	1
Seul,	1
Solange,	1
Sort	1
Sur	57

