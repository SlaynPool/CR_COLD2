root@hadoop-master:~# spark-submit  wordStats.py 
2020-01-20 14:54:02 INFO  SparkContext:54 - Running Spark version 2.4.0
2020-01-20 14:54:02 INFO  SparkContext:54 - Submitted application: WordStats
2020-01-20 14:54:02 INFO  SecurityManager:54 - Changing view acls to: root
2020-01-20 14:54:02 INFO  SecurityManager:54 - Changing modify acls to: root
2020-01-20 14:54:02 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-20 14:54:02 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-20 14:54:02 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2020-01-20 14:54:03 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 44613.
2020-01-20 14:54:03 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-01-20 14:54:03 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-01-20 14:54:03 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-20 14:54:03 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-01-20 14:54:03 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-9e7e6a4b-7ab2-431d-aec8-8950d5106beb
2020-01-20 14:54:03 INFO  MemoryStore:54 - MemoryStore started with capacity 117.0 MB
2020-01-20 14:54:03 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-01-20 14:54:03 INFO  log:192 - Logging initialized @3340ms
2020-01-20 14:54:03 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-20 14:54:03 INFO  Server:419 - Started @3526ms
2020-01-20 14:54:03 INFO  AbstractConnector:278 - Started ServerConnector@7c97963d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-20 14:54:03 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2020-01-20 14:54:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@48e7143f{/jobs,null,AVAILABLE,@Spark}
2020-01-20 14:54:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@33911e13{/jobs/json,null,AVAILABLE,@Spark}
2020-01-20 14:54:04 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7afdb3a{/jobs/job,null,AVAILABLE,@Spark}

........ BEAUCOUP DE LIGNES................

2020-01-20 14:54:09 INFO  SparkHadoopWriter:54 - Job job_20200120145409_0013 committed.
2020-01-20 14:54:09 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2020-01-20 14:54:09 INFO  AbstractConnector:318 - Stopped Spark@7c97963d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-20 14:54:09 INFO  SparkUI:54 - Stopped Spark web UI at http://hadoop-master:4040
2020-01-20 14:54:10 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2020-01-20 14:54:10 INFO  MemoryStore:54 - MemoryStore cleared
2020-01-20 14:54:10 INFO  BlockManager:54 - BlockManager stopped
2020-01-20 14:54:10 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2020-01-20 14:54:10 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2020-01-20 14:54:10 INFO  SparkContext:54 - Successfully stopped SparkContext
2020-01-20 14:54:10 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-01-20 14:54:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a9733db1-37c3-4a7a-ba1c-ce03a1417268/pyspark-01daff45-392c-4d95-970c-f444f42d187b
2020-01-20 14:54:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-5b4e407a-33e9-484f-880c-961d7ca00309
2020-01-20 14:54:10 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a9733db1-37c3-4a7a-ba1c-ce03a1417268
root@hadoop-master:~# cd data_out3/
._SUCCESS.crc    .part-00000.crc  _SUCCESS         part-00000       
root@hadoop-master:~# cat  data_out3/part-00000 
[(u'ne', 3), (u'petit', 2), (u'chat', 2), (u'le', 2), (u'Je', 2)]

