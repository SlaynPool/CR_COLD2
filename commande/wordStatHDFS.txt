root@hadoop-master:~# spark-submit  --master yarn wordStats.py 
2020-01-20 15:07:32 INFO  SparkContext:54 - Running Spark version 2.4.0
2020-01-20 15:07:32 INFO  SparkContext:54 - Submitted application: WordStats
2020-01-20 15:07:32 INFO  SecurityManager:54 - Changing view acls to: root
2020-01-20 15:07:32 INFO  SecurityManager:54 - Changing modify acls to: root
2020-01-20 15:07:32 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-01-20 15:07:32 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-01-20 15:07:32 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2020-01-20 15:07:32 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40793.
2020-01-20 15:07:32 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-01-20 15:07:32 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-01-20 15:07:32 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-01-20 15:07:32 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-01-20 15:07:32 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-131e742c-5ef2-490d-99fc-9ae57a21e4fa
2020-01-20 15:07:32 INFO  MemoryStore:54 - MemoryStore started with capacity 117.0 MB
2020-01-20 15:07:33 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-01-20 15:07:33 INFO  log:192 - Logging initialized @4069ms
2020-01-20 15:07:33 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2020-01-20 15:07:33 INFO  Server:419 - Started @4308ms
2020-01-20 15:07:33 INFO  AbstractConnector:278 - Started ServerConnector@152e57e0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-01-20 15:07:33 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.

---------BEAUCOUP DE LIGNES---------

2020-01-20 15:08:32 INFO  ContextCleaner:54 - Cleaned accumulator 152
2020-01-20 15:08:32 INFO  ContextCleaner:54 - Cleaned accumulator 165
2020-01-20 15:08:32 INFO  ContextCleaner:54 - Cleaned accumulator 135
2020-01-20 15:08:32 INFO  ContextCleaner:54 - Cleaned accumulator 138
2020-01-20 15:08:34 INFO  MemoryStore:54 - MemoryStore cleared
2020-01-20 15:08:34 INFO  BlockManager:54 - BlockManager stopped
2020-01-20 15:08:34 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2020-01-20 15:08:34 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2020-01-20 15:08:34 INFO  SparkContext:54 - Successfully stopped SparkContext
2020-01-20 15:08:34 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-01-20 15:08:34 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7f0e69a2-cc53-47f5-94bc-e0b0e3b64a3f
2020-01-20 15:08:34 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d504c3e4-d32d-42b7-864e-4cd899b642e5
2020-01-20 15:08:34 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7f0e69a2-cc53-47f5-94bc-e0b0e3b64a3f/pyspark-cc76ce3a-24a6-43ea-b667-fb01c311abdd
root@hadoop-master:~# ls
data_out3  file1.txt  file2.txt  file3.txt  file4.txt  files.tar.gz  hdfs  mapper.py  reducer.py  wordStats.py
root@hadoop-master:~# hadoop fs -ls data_out4
Found 3 items
-rw-r--r--   2 root supergroup          0 2020-01-20 15:08 data_out4/_SUCCESS
-rw-r--r--   2 root supergroup          0 2020-01-20 15:08 data_out4/part-00000
-rw-r--r--   2 root supergroup         66 2020-01-20 15:08 data_out4/part-00001
root@hadoop-master:~# hadoop fs -cat data_out4/part-00001
[(u'ne', 3), (u'chat', 2), (u'petit', 2), (u'le', 2), (u'Je', 2)]

